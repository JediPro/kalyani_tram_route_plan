---
title: "Kolkata Lit Meet Schedule"
author: "Pratik C"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, 
                      fig.width = 12, fig.height = 12,
                      echo = TRUE, eval = TRUE)
options(warn = 1)
```

```{r Set environment}
# Load libraries
library(tidyverse)
library(hrbrthemes)
library(lubridate)
library(scales)
library(ggtext)
library(sf)
library(ggrepel)
library(ggpp)
library(ggforce)
library(gg.layers)
library(ggalt)
library(patchwork)
library(ggfittext)
library(rvest)

# Load themes script
source(file = "C:\\Stuff\\Datasets\\vaw_themes.R")

# Set working directory
setwd("C:\\Stuff\\Datasets\\GitHub\\kalyani_tram_route_plan\\")
```

## Existing Tram Networks

```{r Existing Tram Networks}

# Read in city populations -------------------------------------
# Not usiong this as the names are in Unicode, which is difficult to map to ascii names in Wiki file
# Downloaded from https://unstats.un.org/unsd/demographic-social/products/dyb/documents/DYB2024/table08.xls
# table_city_pop <- readxl::read_xlsx(path = "city_pop.xlsx", sheet = "Data", 
#                                     trim_ws = FALSE, skip = 6,
#                                     col_types = c("text", "numeric", "skip", "numeric",
#                                                   "skip", "numeric", "skip", "numeric",
#                                                   "skip", "numeric", "skip", "numeric", 
#                                                   "skip", "numeric", "skip", "numeric", 
#                                                   "skip"),
#                                     col_names = c("territory", "city_pop_total", 
#                                                   "city_pop_male", "city_pop_female",
#                                                   "city_area",
#                                                   "urban_pop_total", "urban_pop_male", 
#                                                   "urban_pop_female", "urban_area")) %>% 
#   # First, extract the year of the estimate for each country
#   mutate(estimate_year = str_extract(string = territory, pattern = "\\d{4}"),
#          # Flag rows containing cities, which are the ones having some values
#          city_flag = !(is.na(city_pop_total) & is.na(urban_pop_total)),
#          continent_flag = (toupper(territory) == territory) & (!city_flag) & (is.na(estimate_year)),
#          country_flag = (!city_flag) & (!continent_flag) & (is.na(estimate_year)),
#          # Create columns for continent and country
#          continent = case_when(continent_flag ~ territory),
#          country = case_when(country_flag ~ territory)) %>% 
#   # Fill values
#   fill(continent, country, estimate_year, .direction = "down") %>% 
#   # Keep only rows for cities
#   filter(city_flag) %>% 
#   # Remove helper columns
#   select(-contains("flag")) %>% 
#   # Clean country and continent names
#   mutate(across(.cols = c(country, continent), 
#                 .fns = ~str_replace_all(string = .x, pattern = "-.*|\\d", 
#                                         replacement = "")),
#          # Remove brackets
#          territory = str_replace_all(string = territory, pattern = "\\(.*", replacement = "") %>% trimws())

# Fetch list of tram and metro systems ---------------------------
table_lrt_systems <- read_html("https://en.wikipedia.org/wiki/List_of_tram_and_light_rail_transit_systems") %>% 
  # Reqad in all tables in the file
  html_table(header = TRUE) %>% 
  # convert to tibble for easier wrangling
  as_tibble_col(column_name = "tbl") %>% 
  # Extract number of columns in each table
  mutate(num_col = map_int(.x = tbl, .f = ncol)) %>% 
  # Keep only tables with at least 8 columns, as they correspond to data we need
  filter(num_col >= 8) %>% 
  # Unnest all
  select(-num_col) %>% 
  # Convert to character all columns in the files
  mutate(tbl = map(.x = tbl, .f = as_tibble),
         # Rename a column in one of the files
         tbl = map(.x = tbl, .f = function(x){ x %>% 
             rename(Stations = c(contains("Stations")))}),
         tbl = map(.x = tbl, .f = function(x){ x %>% 
             mutate(across(.cols = c(Stations,  Lines), .fns = as.character))})) %>% 
  unnest(cols = tbl) %>% 
  # Rename columns
  rename(city = Location, country = Country, system = System, year = `Year opened`,
         stations = Stations, lines = Lines, length = `System length`,
         type = Type, ridership = `Annual ridership(millions)`) %>% 
  # Process fields
  mutate(across(.cols = everything(), 
                .fns = ~str_replace_all(string = .x, pattern = "\\[.*|,.*", 
                                        replacement = "")),
         # Convert to numeric
         across(.cols = c(year, stations, lines), 
                .fns = ~str_extract(string = .x, pattern = "\\d.*") %>% as.integer()),
         length = str_extract(string = length, pattern = "(.*)[\\h]km", group = 1) %>% as.numeric()) %>% 
  drop_na(year) %>% 
  # rename Washington
  mutate(city = case_when(city == "Washington" ~ "Washington DC", TRUE ~ city))

# Download world cities database from simplemaps to map ascii names to unicode names --------------------
table_city_name <- readxl::read_xlsx(path = "worldcities.xlsx") %>% 
  # Recode country names that do not match Popn table
  mutate(country = case_match(.x = country, "Korea, North" ~ "North Korea",
                              "Czechia" ~ "Czech Republic",
                              .default = country),
         city_ascii = case_when(city_ascii == "Washington" & admin_name == "District of Columbia" ~ "Washington DC",
                                TRUE ~ city_ascii),
         city = case_when(city == "Washington" & admin_name == "District of Columbia" ~ "Washington DC",
                                TRUE ~ city),
         popn = population,
         across(c(city, city_ascii, country), toupper)) %>% 
  # Some city names are duplicated, keep only the entry per city-country with highest popn
  group_by(city_ascii, country) %>% 
  slice_max(order_by = population, n = 1) %>% ungroup() %>% 
  # Recode city names
  mutate(city_ascii = case_match(.x = city_ascii,
                                 "AR RAYYAN" ~ "AL RAYYAN",
                                "BRANDENBURG" ~ "BRANDENBURG AN DER HAVEL",
                                "CH'ONGJIN" ~ "CHONGJIN",
                                "ERFURT" ~ "ERFURT",
                                "FRANKFURT" ~ "FRANKFURT AM MAIN",
                                "GALATI" ~ "GALAȚI",
                                "GENT" ~ "GHENT",
                                "COPENHAGEN" ~ "GREATER COPENHAGEN",
                                "HANNOVER" ~ "HANOVER",
                                "IASI" ~ "IAȘI",
                                "JINAN" ~ "JINAN ",
                                "KAMAKURAYAMA" ~ "KAMAKURA",
                                "KATOWICE" ~ "KATOWICE AND ITS AREA",
                                "KRASNOTUR'INSK" ~ "KRASNOTURYINSK",
                                "LUZHANG" ~ "LIJIANG",
                                "MINNEAPOLIS" ~ "MINNEAPOLIS–SAINT PAUL",
                                "NABEREZHNYYE CHELNY" ~ "NABEREZHNYE CHELNY",
                                "TAIPEI" ~ "NEW TAIPEI",
                                "NEWCASTLE" ~ "NEWCASTLE UPON TYNE",
                                "NIZHNIY NOVGOROD" ~ "NIZHNY NOVGOROD",
                                "NIZHNIY TAGIL" ~ "NIZHNY TAGIL",
                                "NAVAPOLATSK" ~ "NOVOPOLOTSK",
                                "OREL" ~ "ORYOL",
                                "PADOVA" ~ "PADUA",
                                "PLOIESTI" ~ "PLOIEȘTI",
                                "PORT LOUIS" ~ "PORT LOUIS AND THE DISTRICT OF PLAINES WILHEMS",
                                "RESITA" ~ "REȘIȚA",
                                "ROSTOV" ~ "ROSTOV-ON-DON",
                                "SANTA CRUZ" ~ "SANTA CRUZ DE TENERIFE",
                                "SANTOS" ~ "SANTOS AND THE METROPOLITAN REGION OF BAIXADA SANTISTA",
                                "SEVILLA" ~ "SEVILLE",
                                "STARYY OSKOL" ~ "STARY OSKOL",
                                "TEL AVIV-YAFO" ~ "TEL AVIV",
                                "TIMISOARA" ~ "TIMIȘOARA",
                                "USOL'YE-SIBIRSKOYE" ~ "USOLYE-SIBIRSKOYE",
                                "VITSYEBSK" ~ "VITEBSK",
                                "YEVPATORIIA" ~ "YEVPATORIA",
                                "" ~ "İZMIT"
))

# Create table combining system and population information -----------------------
data_lrt_pop <- table_lrt_systems %>% 
  # Some cities have multiple rows, sum up the values for them
  group_by(city, country) %>% 
  summarise(across(.cols = c(stations, lines, length), 
                   .fns = ~sum(.x, na.rm = TRUE)),
            .groups = "drop") %>% 
  mutate(across(c(city, country), toupper)) %>% 
  # # Map popn
  # left_join(y = table_city_pop %>% 
  #             mutate(popn = case_when(is.na(city_pop_total) ~ urban_pop_total,
  #                                     TRUE ~ city_pop_total),
  #                    across(c(territory, country), toupper)) %>% 
  #             select(territory, country, popn), 
  #           by = c("city" = "territory", "country")) %>% 
  # Map popn
  left_join(y = table_city_name %>% select(city_ascii, country, popn),
            by = c("city" = "city_ascii", "country")) %>% 
  left_join(y = table_city_name %>% select(city, country, popn),
            by = c("city" = "city", "country"), suffix = c("_1", "_2")) %>% 
  mutate(popn = case_when(is.na(popn_1) ~ popn_2, TRUE ~ popn_1)) %>% 
  arrange(city) %>% 
  filter(is.na(popn))
  
  
```

## Schedule for 2026

```{r 2026}
# Extract event text from page -----------------
table_events <- read_html(x = "https://kolkatalitmeet.in/2026/") %>% 
  # Individual elements
  html_elements(css = "div.relative.section-div") %>% 
  # Extract text, cleaning up a bit
  html_text2() %>% 
  # Convert to tibble
  as_tibble_col(column_name = "event_raw")

# Write to disk ----------------------------
arrow::write_parquet(x = table_events, sink = "table_events_2026.parquet")

# Read from disk -------------------------
table_events <- arrow::read_parquet(file = "table_events_2026.parquet")

# Colours fetched from logo and shaded -------------------
# Primary
colorspace::lighten(col = "#EB2228", amount = 0.3, space = "HCL", method = "absolute") #FFB5B6
# Secondary
colorspace::lighten(col = "#1150A0", amount = 0.4, space = "HCL", method = "absolute") #7B9CE9

# Process ---------------------------------
data_events <- table_events %>% 
  # Separate into separate columns
  separate_wider_delim(cols = event_raw, delim = regex("(\\n{1,2})"), 
                       names = c("date", "time", "venue", "title", "blurb", "panel"),
                       too_few = "align_start", too_many = "merge") %>% 
  # Trim all whitespace
  mutate(across(.cols = everything(), .fns = ~trimws(x = ., which = "both"))) %>% 
  # Extract panel names
  mutate(panel = str_replace_all(string = panel, pattern = "(\\n{1,2})", replacement = " | ")) %>% 
  # Convert time stamp
  unite(col = start_time, date, time, sep = " ", remove = TRUE) %>% 
  mutate(start_time = parse_date_time(x = start_time, orders = c("%A | %B %d, %Y %I:%M %p", "%A | %d %B, %Y %I:%M %p")),
         date = date(start_time),
         # truncate venue names
         venue = str_replace_all(string = venue, pattern = " \\(.*", replacement = ""),
         # Standardize spelling
         venue = str_replace_all(string = venue, pattern = "Ka[lL]am", replacement = "KaLaM")) %>% 
  # Sort in chronological order
  arrange(start_time) %>% 
  # Calculate end time
  group_by(date, venue) %>% 
  mutate(end_time = lead(start_time)) %>% 
  relocate(date, .before = start_time) %>% 
  relocate(end_time, .after = start_time) %>% 
  # Fill in blanks, assuming 50m duration
  mutate(end_time = case_when(is.na(end_time) ~ start_time + minutes(50),
                              # If end time is more than 50m, truncate to 50
                              interval(start = start_time, 
                                       end = end_time)/minutes(1) > 50 ~ start_time + minutes(50),
                              TRUE ~ end_time),
         # Index venues in order to assign order and colours
         venue_label = case_match(.x = venue,
                                  "KaLaM Lawns" ~ 2,
                                  "KaLaM Hub" ~ 1,
                                  .default = 0),
         # Set date to same date for every time object
         across(.cols = c(start_time, end_time), 
                .fns = function(x){update(object = x, year = 2026, month = 1, mday = 15)}),
         # Session index at venue
         session_even = row_number() %% 2,
         # Set fill colour
         fill = case_when(venue_label == 2 & session_even == 0 ~ "#FFB5B6",
                          venue_label == 2 & session_even == 1 ~ "#EB2228",
                          venue_label == 1 & session_even == 0 ~ "#9BB7FF",
                          venue_label == 1 & session_even == 1 ~ "#1150A0",
                          venue_label == 0 & session_even == 0 ~ "#E6F5D0",
                          venue_label == 0 & session_even == 1 ~ "#B8E186"),
         text_colour = case_when(venue_label >= 1 & session_even == 0 ~ "black",
                                 venue_label >= 1 & session_even == 1 ~ "white",
                                 venue_label == 0 ~ "black")) %>% 
  ungroup() %>% 
  # Remove all venues except the 2 primary ones
  filter(venue_label > 0) %>% 
  # Truncate titles
  mutate(title = str_trunc(string = title, width = 50, side = "right"),
         panel = str_trunc(string = panel, width = 70, side = "right"))

# Fetch logo from webpage ------------------------------------------
data_image <- tibble(date = min(data_events$date), img = "https://kolkatalitmeet.in/2026/wp-content/themes/klm/assets/logo/klm.png")

# Visualize -----------------------------------------
plot_schedule <- data_events %>% 
  ggplot() +
  # Date
  # geom_text_npc(data = . %>% group_by(date) %>% slice_head(n = 1),
  #               mapping = aes(npcx = 0.01, npcy = 0.5, 
  #                             label = format(x = date, format = "%d")),
  #               family = "Titillium Web", colour = "grey7", alpha = 0.3,
  #               hjust = 0.5, vjust = 0.5, fontface = "bold", size = 30) +
  # Rect for date
  geom_fit_text(data = . %>% group_by(date) %>% slice_head(n = 1),
                mapping = aes(xmin = start_time - minutes(20), ymin = 0.5, 
                              xmax = start_time, ymax = 2.5, 
                              label = format(x = date, format = "%d")), 
                family = "Titillium Web", colour = "grey7", alpha = 0.3,
                hjust = 0.5, vjust = 0.5, fontface = "bold", size = 30) +
  # Rects
  geom_rect(mapping = aes(xmin = start_time, ymin = venue_label - 0.5,
                          xmax = end_time, ymax = venue_label + 0.5,
                       fill = fill), 
            colour = "white", linewidth = 1) +
  # Labels
  geom_fit_text(mapping = aes(xmin = start_time, ymin = venue_label,
                              xmax = end_time, ymax = venue_label + 0.5,
                       label = title, colour = text_colour), size = 15, 
                family = "Titillium Web", fontface = "bold", min.size = 8, 
                place = "topleft", fullheight = TRUE, reflow = TRUE) +
  # Labels for panel
  geom_fit_text(mapping = aes(xmin = start_time, ymin = venue_label - 0.5,
                       xmax = end_time, ymax = venue_label,
                       label = panel, colour = text_colour), size = 12,
                family = "Titillium Web", fontface = "bold", min.size = 7, 
                place = "bottomright", fullheight = TRUE, reflow = TRUE) +
  # Show image
  ggimage::geom_image(data = data_image, 
                      mapping = aes(x = as_datetime(paste(min(date(data_events$start_time)), "16:55:00 UTC")), 
                                    y = 1.3, image = img),
                      by = "height", size = 0.8, hjust = 0) +
  # Scales
  scale_x_datetime(name = NULL, expand = expansion(mult = c(0.02, 0.02)),
                     labels = time_format(format = "%l %p"), breaks = "2 hours") +
  scale_y_continuous(name = NULL, breaks = NULL,
                     expand = expansion(mult = c(0.02, 0.02))) +
  scale_colour_identity(guide = NULL) +
  scale_fill_identity(guide = NULL) +
  # Facets
  facet_wrap(facets = vars(date), ncol = 1) +
  # Labels
  labs() +
  theme_vaw_light() +
  theme(panel.grid.major.y = element_blank(),
        panel.border = element_rect(fill = NA, colour = "grey29", linewidth = 1),
        strip.text.x = element_blank())

ggsave(filename = "KLM_Schedule_2026.png", plot = plot_schedule, device = "png", 
       width = 70, height = 35, units = "cm", dpi = 300, limitsize = FALSE)
```